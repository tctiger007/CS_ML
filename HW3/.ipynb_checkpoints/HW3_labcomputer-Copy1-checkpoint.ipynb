{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "from pylab import show\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "#from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "#data = np.loadtxt(\"C:/Users/wwang75/Documents/CS/CS412/HW/HW2/data.csv\")\n",
    "data = np.loadtxt(\"/Users/wangfei/Documents/Courses/CS/CS412/HW/HW1/data.csv\")\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(data)\n",
    "features = []\n",
    "digits = []\n",
    "for row in data:\n",
    "    if(row[0]==1 or row[0]==5):\n",
    "        features.append(row[1:])\n",
    "        digits.append(str(row[0]))\n",
    "numTrain = int(len(features)*0.2)\n",
    "trainFeatures = features[:numTrain]\n",
    "testFeatures = features[numTrain:]\n",
    "trainDigits = digits[:numTrain]\n",
    "testDigits = digits[numTrain:]\n",
    "\n",
    "colors = []\n",
    "for index in range(len(trainFeatures)):\n",
    "    if(trainDigits[index]==\"1.0\"):\n",
    "        colors.append(\"b\")\n",
    "    else:\n",
    "        colors.append(\"r\")\n",
    "        \n",
    "def ExtractFeat(dataset,label):\n",
    "    X = []   ##mean\n",
    "    Y = []   ##std\n",
    "    colors = []\n",
    "    for index in range(len(dataset)):\n",
    "        X.append(np.mean(dataset[index]))\n",
    "        Y.append(np.std(dataset[index]))  \n",
    "        if(label[index]==\"1.0\"):\n",
    "            colors.append(\"b\")\n",
    "        else:\n",
    "            colors.append(\"r\")\n",
    "    return [X, Y, colors];\n",
    "\n",
    "##normalization     \n",
    "def normalize(lists):\n",
    "    norm = [i * 2/(max(lists)-min(lists))+\n",
    "            1-2*max(lists)/(max(lists)-min(lists)) for i in lists]\n",
    "    return norm;\n",
    "##normalize two features\n",
    "###training features\n",
    "Xnorm = normalize(ExtractFeat(trainFeatures,trainDigits)[0])\n",
    "Ynorm = normalize(ExtractFeat(trainFeatures,trainDigits)[1])\n",
    "Xnorm = np.asarray(Xnorm)\n",
    "Ynorm = np.asarray(Ynorm)\n",
    "simpleTrain = np.column_stack((Xnorm,Ynorm))\n",
    "###testing features\n",
    "Xnorm_test = normalize(ExtractFeat(testFeatures,testDigits)[0])\n",
    "Ynorm_test = normalize(ExtractFeat(testFeatures,testDigits)[1])\n",
    "Xnorm_test = np.asarray(Xnorm_test)\n",
    "Ynorm_test = np.asarray(Ynorm_test)\n",
    "simpleTest = np.column_stack((Xnorm_test,Ynorm_test))\n",
    "\n",
    "xPred = []\n",
    "yPred = []\n",
    "for xP in range(-100,100):\n",
    "    xP = xP/100\n",
    "    for yP in range(-100,100):\n",
    "        yP = yP/100\n",
    "        xPred.append(xP)\n",
    "        yPred.append(yP)\n",
    "\n",
    "coordinate = list(zip(xPred,yPred))\n",
    "\n",
    "def pred(model):\n",
    "    preds = model.predict(coordinate)\n",
    "    cPred = []\n",
    "    for i in range(len(coordinate)):\n",
    "        if(preds[i] == \"1.0\"):\n",
    "            cPred.append(\"b\")\n",
    "        else:\n",
    "            cPred.append(\"r\")\n",
    "    return cPred;            \n",
    "\n",
    "img_path = '/Users/wangfei/Documents/Courses/CS/CS412/HW/HW3/figures/'\n",
    "#define plot function: for plotting decision boundary figures and CV_error figures \n",
    "def plot(grid1,grid2,plotNum,fileName,plotType,model,\n",
    "         subtitle,ylimL,ylimU,xlab,ylab):   \n",
    "    fig = mp.figure()\n",
    "    if(plotNum==1):\n",
    "        mp.title(fileName)\n",
    "        if(plotType==1):\n",
    "            mp.scatter(Xnorm, Ynorm, c=colors, s=3)\n",
    "            mp.scatter(xPred, yPred, s=3, c=pred(model),alpha=.2)\n",
    "        elif(plotType==2):\n",
    "            mp.errorbar(c, model[0], marker='s', yerr=model[1],fmt='o',\n",
    "                        markersize=2, capsize=1.5, elinewidth=1)\n",
    "            mp.xscale('log')\n",
    "        else:\n",
    "            print('Plot Type not defined.')\n",
    "        mp.ylim(ylimL,ylimU)\n",
    "        mp.xlabel(xlab)\n",
    "        mp.ylabel(ylab)\n",
    "        mp.savefig(img_path + fileName, dpi = 300)\n",
    "    else:\n",
    "        for i in range(1,(plotNum+1)):\n",
    "            ax = fig.add_subplot(grid1,grid2,i)\n",
    "            if(plotType==1):\n",
    "                ax.scatter(Xnorm, Ynorm, c=colors, s=3)\n",
    "                ax.scatter(xPred, yPred, s=3, c=pred(model[i-1]),alpha=.04)\n",
    "            elif(plotType==2):\n",
    "                ax.errorbar(c, model[i-1][0], marker='s', yerr=model[i-1][1],fmt='o',\n",
    "                        markersize=2, capsize=1.5, elinewidth=1)\n",
    "                ax.set_xscale('log')\n",
    "            else:\n",
    "                print('Plot Type not defined.')\n",
    "            ax.set_title(subtitle[i-1])\n",
    "            ax.set_ylim(ylimL,ylimU)\n",
    "            ax.set_xlabel(xlab)\n",
    "            ax.set_ylabel(ylab)\n",
    "            mp.subplots_adjust(top=0.92, bottom=0.12, left=0.11, right=0.94, \n",
    "                               hspace=0.60, wspace=0.45)\n",
    "            mp.savefig(img_path + fileName, dpi = 300)\n",
    "    return show();       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumbHidLayer = Number of hidden layers; NumbNodes = number of nodes/layer\n",
    "#y = true labels, X = design matrix, data\n",
    "#CV errors \n",
    "def cv_err_NN(NumbHidLayer,NumbNodes,X,y,learningrate=0.001,earlystop = False):\n",
    "    err_bar = []\n",
    "    err_mean = []\n",
    "    runtime = []\n",
    "    for i in range(0, len(NumbHidLayer)):\n",
    "        start_time = time.time()\n",
    "        for j in range(0, len(NumbNodes)):\n",
    "            NN = MLPClassifier(hidden_layer_sizes=(NumbNodes[j],NumbHidLayer[i]),activation = \"relu\",\n",
    "                               max_iter=10000,alpha=0,epsilon=0.001,solver = \"adam\",\n",
    "                               learning_rate_init=learningrate,early_stopping=earlystop)\n",
    "            NN_fit = NN.fit(X,y)\n",
    "            acc = cross_val_score(NN, X, y, cv=10)\n",
    "            runtime.append(time.time() - start_time)\n",
    "            err = 1 - acc\n",
    "            err_mean.append(err.mean())\n",
    "            err_bar.append(1.96 * err.std())\n",
    "#             print('Hidden Layer = '+ repr(NumbHidLayer[i]) + ' Nodes per Layer = ' + \n",
    "#                   repr(NumbNodes[j]) + ': CV_err = ' + repr(err.mean()) + \n",
    "#                   ' and Error_bar = ' + repr(1.96*err.std()))\n",
    "    return np.array([err_mean, err_bar,np.multiply(runtime,1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvErrorOld = cv_err_NN([1,2,5,10],[2,5,10,50,100],simpleTrain,trainDigits)\n",
    "cvErrorOld\n",
    "# array([[1.85094086e-01, 1.79045699e-01, 2.08534946e-01, 1.34375000e-01,\n",
    "#         7.09341398e-02, 1.11404570e-01, 1.61760753e-01, 4.20430108e-02,\n",
    "#         3.22580645e-03, 6.98588710e-02, 1.43158602e-01, 3.54905914e-02,\n",
    "#         1.62432796e-02, 6.45161290e-03, 3.22580645e-03, 8.72110215e-02,\n",
    "#         2.58198925e-02, 1.63440860e-02, 6.45161290e-03, 6.45161290e-03],\n",
    "#        [2.95302803e-01, 2.61053801e-01, 2.97215585e-01, 3.10406740e-01,\n",
    "#         2.62961035e-01, 2.37377049e-01, 2.79270952e-01, 1.85501758e-01,\n",
    "#         1.89677419e-02, 2.58883504e-01, 2.78072384e-01, 7.18153616e-02,\n",
    "#         4.32255819e-02, 2.52903226e-02, 1.89677419e-02, 2.34974023e-01,\n",
    "#         4.79074574e-02, 4.33638700e-02, 2.52903226e-02, 2.52903226e-02],\n",
    "#        [1.13211250e+04, 1.88550322e+04, 2.75967860e+04, 3.79106820e+04,\n",
    "#         5.32653382e+04, 9.69889474e+03, 1.78222311e+04, 3.11327109e+04,\n",
    "#         4.36247277e+04, 5.58709178e+04, 9.27538800e+03, 2.17990239e+04,\n",
    "#         3.39435349e+04, 4.43565919e+04, 5.67064559e+04, 9.45899105e+03,\n",
    "#         2.08835638e+04, 3.11254900e+04, 4.10187690e+04, 5.12829340e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the lowest upper bound of CV_error and runtime\n",
    "def opt(x1,x2,x3):\n",
    "    return [np.argmin(np.add(x1,x2)), np.multiply(x3,1000)]\n",
    "    \n",
    "x1 = cvErrorOld[0]\n",
    "x2 = cvErrorOld[1]\n",
    "np.argmin(np.add(x1, x2))\n",
    "x3 = cvErrorOld[2]\n",
    "\n",
    "opt(x1,x2,x3)\n",
    "\n",
    "# [8, array([11321125.03051758, 18855032.20558167, 27596786.02218628,\n",
    "#         37910681.96296692, 53265338.18244934,  9698894.739151  ,\n",
    "#         17822231.05430603, 31132710.9336853 , 43624727.72598267,\n",
    "#         55870917.79708862,  9275388.00239563, 21799023.86665344,\n",
    "#         33943534.85107422, 44356591.93992615, 56706455.94596863,\n",
    "#          9458991.05072021, 20883563.75694275, 31125489.95018005,\n",
    "#         41018769.02580261, 51282933.95042419])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_opt = MLPClassifier(hidden_layer_sizes=(50,2),activation = \"relu\", epsilon=0.001, \n",
    "                       max_iter=10000,alpha=0, solver = \"adam\").fit(simpleTrain,trainDigits)\n",
    "plot(grid1=1,grid2=1,plotNum=1,fileName='Figure3_1',plotType=1,model=NN_opt,\n",
    "     subtitle=(''),ylimL=-1,ylimU=1,xlab='Mean Intensity',ylab='Intensity SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For your optimum model, try increasing and decreasing the learning rate from the default (0.001). Discuss the tradeoff here between runtime and accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnPara = np.logspace(-6,3,num=10,endpoint=True)\n",
    "learnTime = []\n",
    "learnErrorMean = [] #CV error Mean\n",
    "learnErrorSD = []   #CV error 1.96*SD\n",
    "for index in range(0,10):\n",
    "    learnTime.append(cv_err_NN([2],[50],simpleTrain,trainDigits,learningrate=learnPara[index])[2])\n",
    "    learnErrorMean.append((cv_err_NN([2],[50],simpleTrain,trainDigits,learningrate=learnPara[index])[0]))\n",
    "    learnErrorSD.append((cv_err_NN([2],[50],simpleTrain,trainDigits,learningrate=learnPara[index])[1]))\n",
    "learnErrorMean, learnErrorSD, learnTime \n",
    "# ([array([0.46347446]),\n",
    "#   array([0.53867608]),\n",
    "#   array([0.50225134]),\n",
    "#   array([0.10745968]),\n",
    "#   array([0.07298387]),\n",
    "#   array([0.09688172]),\n",
    "#   array([0.31387769]),\n",
    "#   array([0.33000672]),\n",
    "#   array([0.46458333]),\n",
    "#   array([0.39882392])],\n",
    "#  [array([0.3989728]),\n",
    "#   array([0.32681087]),\n",
    "#   array([0.39974525]),\n",
    "#   array([0.19339933]),\n",
    "#   array([0.31040674]),\n",
    "#   array([0.19613592]),\n",
    "#   array([0.15813426]),\n",
    "#   array([0.19904022]),\n",
    "#   array([0.32765327]),\n",
    "#   array([0.2756706])],\n",
    "#  [array([193.51482391]),\n",
    "#   array([2859.68494415]),\n",
    "#   array([6904.93988991]),\n",
    "#   array([12339.54572678]),\n",
    "#   array([3594.165802]),\n",
    "#   array([1559.7577095]),\n",
    "#   array([337.33916283]),\n",
    "#   array([364.91918564]),\n",
    "#   array([225.82602501]),\n",
    "#   array([159.05213356])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early1 = MLPClassifier(hidden_layer_sizes=(900,5),activation = \"relu\",epsilon=0.001,max_iter=10000,\n",
    "                       alpha=0, solver = \"adam\",early_stopping=False).fit(simpleTrain,trainDigits)\n",
    "early2 = MLPClassifier(hidden_layer_sizes=(900,5),activation = \"relu\",epsilon=0.001,max_iter=10000,\n",
    "                       alpha=0, solver = \"adam\",early_stopping=True).fit(simpleTrain,trainDigits)\n",
    "plot(grid1=2,grid2=1,plotNum=2,fileName='test',plotType=1,\n",
    "     model=[early1,early2],\n",
    "     subtitle=('early stop = False','early stop = True'),ylimL=-1,ylimU=1,xlab='Mean Intensity',ylab='Intensity SD')\n",
    "[1-early1.score(simpleTrain,trainDigits), 1-early1.score(simpleTest,testDigits),\n",
    "1-early2.score(simpleTrain,trainDigits), 1-early2.score(simpleTest,testDigits)]\n",
    "# [0.0032051282051281937,\n",
    "#  0.009607686148919159,\n",
    "#  0.16666666666666663,\n",
    "#  0.1409127301841473]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New data set Transfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfusion = np.loadtxt(\"transfusion_data.txt\",delimiter=',',skiprows=1)\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(transfusion)\n",
    "DonateNumTrain = int(transfusion.shape[0]*0.7)\n",
    "labelDonate = transfusion[0:DonateNumTrain,4]\n",
    "trainDonate = transfusion[0:DonateNumTrain,0:3]\n",
    "cv_err_NN([1,2,5],[2,5,10],trainDonate,labelDonate)\n",
    "# array([[3.88879482e-01, 3.45664678e-01, 2.52341020e-01, 3.49510832e-01,\n",
    "#         3.11956405e-01, 2.58110251e-01, 2.52341020e-01, 2.52341020e-01,\n",
    "#         3.65873784e-01],\n",
    "#        [4.11561169e-01, 3.90082854e-01, 9.42389773e-03, 3.85632669e-01,\n",
    "#         2.94380943e-01, 3.37018779e-02, 9.42389773e-03, 1.93119616e-02,\n",
    "#         3.76673731e-01],\n",
    "#        [2.37295008e+03, 6.29459691e+03, 1.32476530e+04, 2.03101683e+03,\n",
    "#         4.20796990e+03, 6.64119077e+03, 8.32352877e+02, 2.19262505e+03,\n",
    "#         3.39608884e+03]])\n",
    "#total data set \n",
    "labelDonate_total = transfusion[:,4]\n",
    "trainDonate_total = transfusion[:,0:3]\n",
    "cv_err_NN([1,2,5],[2,5,10],trainDonate_total,labelDonate_total)\n",
    "# array([[3.45333333e-01, 2.40612613e-01, 2.89945946e-01, 2.37945946e-01,\n",
    "#         2.39279279e-01, 3.43243243e-01, 3.94666667e-01, 4.49927928e-01,\n",
    "#         2.27225225e-01],\n",
    "#        [4.11562060e-01, 1.87824364e-02, 3.07204589e-01, 8.05189189e-03,\n",
    "#         1.21384035e-02, 4.10537951e-01, 4.73270822e-01, 4.98239564e-01,\n",
    "#         3.59614835e-02],\n",
    "#        [4.35391593e+03, 6.74995303e+03, 1.08982668e+04, 5.66308904e+03,\n",
    "#         1.14907222e+04, 1.54770792e+04, 1.40117908e+03, 5.40724611e+03,\n",
    "#         8.92803311e+03]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt([3.88879482e-01, 3.45664678e-01, 2.52341020e-01, 3.49510832e-01,\n",
    "        3.11956405e-01, 2.58110251e-01, 2.52341020e-01, 2.52341020e-01,\n",
    "        3.65873784e-01],\n",
    "       [4.11561169e-01, 3.90082854e-01, 9.42389773e-03, 3.85632669e-01,\n",
    "        2.94380943e-01, 3.37018779e-02, 9.42389773e-03, 1.93119616e-02,\n",
    "        3.76673731e-01],\n",
    "       [2.37295008e+03, 6.29459691e+03, 1.32476530e+04, 2.03101683e+03,\n",
    "        4.20796990e+03, 6.64119077e+03, 8.32352877e+02, 2.19262505e+03,\n",
    "        3.39608884e+03])\n",
    "#70% data as training dataset \n",
    "# [2, array([ 2372950.08 ,  6294596.91 , 13247653.   ,  2031016.83 ,\n",
    "#          4207969.9  ,  6641190.77 ,   832352.877,  2192625.05 ,\n",
    "#          3396088.84 ])]\n",
    "\n",
    "# total model \n",
    "# [3, array([ 4353915.93,  6749953.03, 10898266.8 ,  5663089.04, 11490722.2 ,\n",
    "#         15477079.2 ,  1401179.08,  5407246.11,  8928033.11])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "TestlabelDonate = transfusion[DonateNumTrain:,4]\n",
    "testDonate = transfusion[DonateNumTrain:,0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cart = DecisionTreeClassifier()\n",
    "#num_trees = 100\n",
    "# bag1 = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=100)\n",
    "# results = model_selection.cross_val_score(bag1, testDonate, TestlabelDonate, cv=30)\n",
    "# print(results)\n",
    "\n",
    "def cv_err_bagging(NumbHidLayer,NumbNodes,X,y,learningrate=0.001,earlystop = False):\n",
    "    err_bar = []\n",
    "    err_mean = []\n",
    "    for i in range(0, len(NumbHidLayer)):\n",
    "        start_time = time.time()\n",
    "        for j in range(0, len(NumbNodes)):\n",
    "            NN = MLPClassifier(hidden_layer_sizes=(NumbNodes[j],NumbHidLayer[i]),activation = \"relu\",\n",
    "                               max_iter=10000,alpha=0,epsilon=0.001,solver = \"adam\",\n",
    "                               learning_rate_init=learningrate,early_stopping=earlystop)\n",
    "            bagging = BaggingClassifier(base_estimator=NN)\n",
    "            acc = cross_val_score(bagging, testDonate, TestlabelDonate, cv=30)\n",
    "            err = 1 - acc\n",
    "            err_mean.append(err.mean())\n",
    "            err_bar.append(1.96 * err.std())\n",
    "    return np.array([err_mean, err_bar])\n",
    "\n",
    "#cv_err_bagging([1,5],[2,50], testDonate, TestlabelDonate)\n",
    "cv_err_bagging([1],[2], testDonate, TestlabelDonate)           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
